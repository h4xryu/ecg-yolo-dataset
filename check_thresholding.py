import torch
from src import plot_results, plot_results_with_target
from src import Detector, Denoising, Digitization, Classifier, ClassifierRaw
import numpy as np
import time
import os
import re
import cv2
import matplotlib
matplotlib.use('TkAgg')  # 또는 'Qt5Agg'로 변경 가능
import matplotlib.pyplot as plt
import pandas as pd
import random
from scipy.stats import norm

# DEVICE = torch.device('cpu') # using CPU
DEVICE = torch.device('cpu' if torch.cuda.device_count() == 0 else 'cuda')
start = time.time()


def sort_key(filename):
    # 파일명에서 숫자 추출 (예: 'MR000001-0_thr_12.jpg'에서 12를 추출)
    numbers = re.findall(r'\d+', filename)
    # 정렬을 위해 추출된 숫자를 정수로 변환
    return [int(num) for num in numbers]

def get_image(lead_path, path):
    image_list = []
    for file in path:
        file_path = lead_path + f'/{file}'
        image_list.append(cv2.imread(file_path))
    return image_list

def create_directory_if_empty(directory_path):
    # 디렉토리가 존재하지 않거나, 비어 있으면 생성
    if not os.path.exists(directory_path) or not os.listdir(directory_path):
        os.makedirs(directory_path, exist_ok=True)

def get_all_directories(directory_path):
    # 주어진 디렉토리 내에서 하위 디렉토리만 가져옴
    return [name for name in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, name))]

def save_data(diagnosis_classes, data_list, extracted_result_list, target_result_list, dir, filename):
    # extracted_result_list와 target_result_list를 백분율로 변환 후 정수로 반올림
    percent_extracted = [np.round(result * 100).astype(int) for result in extracted_result_list]
    percent_target = [np.round(result * 100).astype(int) for result in target_result_list]

    # 데이터 리스트 길이 확인 및 열 이름 생성
    assert len(data_list) == len(percent_extracted) == len(percent_target), "데이터 리스트와 결과 리스트의 길이가 일치해야 합니다."

    # 각 데이터에 대해 extracted 및 target 결과를 열로 병합
    combined_results = []
    for extracted, target in zip(percent_extracted, percent_target):
        combined_results.append(np.column_stack((extracted, target)))

    # 모든 결과를 진단 클래스를 기준으로 행 방향으로 정렬
    all_results = np.column_stack(combined_results)  # 진단 클래스별로 모든 데이터 병합

    # 멀티 인덱스 설정: 첫 번째 행에 데이터 이름, 두 번째 행에 extracted/target
    columns = pd.MultiIndex.from_product([data_list, ['extracted', 'target']], names=['Data', 'Type'])

    # DataFrame 생성
    df = pd.DataFrame(all_results, index=diagnosis_classes, columns=columns)

    # 엑셀 파일로 저장
    save_dir = dir + filename
    df.to_excel(save_dir)

def draw_extracted_on_paper(extracted, papers, save_dir):
    for i in range(13):
        plt.figure()
        plt.imshow(papers[i], cmap='gray')
        plt.plot(extracted[i])
        plt.savefig(save_dir + f'image_{i}')

def save_image_list(save_dir, dir_name, image_list):
    for i, image in enumerate(image_list):
        cv2.imwrite(save_dir+dir_name+f'_shadowed_{i}.png',image)

# SHADOW ###############################################################################################################
def generate_spot_light_mask(mask_size, position=None, max_brightness=255, min_brightness=0, mode="gaussian", linear_decay_rate=None, speedup=False):
    """
    Generate decayed light mask generated by spot light given position, direction. Multiple spotlights are accepted.
    Args:
        mask_size: tuple of integers (w, h) defining generated mask size
        position: list of tuple of integers (x, y) defining the center of spotlight light position,
                  which is the reference point during rotating
        max_brightness: integer that max brightness in the mask
        min_brightness: integer that min brightness in the mask
        mode: the way that brightness decay from max to min: linear or gaussian
        linear_decay_rate: only valid in linear_static mode. Suggested value is within [0.2, 2]
        speedup: use `shrinkage then expansion` strategy to speed up vale calculation
    Return:
        light_mask: ndarray in float type consisting value from max_brightness to min_brightness. If in 'linear' mode
                    minimum value could be smaller than given min_brightness.
    """
    if position is None:
        position = [(random.randint(0, mask_size[0]), random.randint(0, mask_size[1]))]
    if linear_decay_rate is None:
        if mode == "linear_static":
            linear_decay_rate = random.uniform(0.25, 1)
    assert mode in ["linear", "gaussian"], \
        "mode must be linear_dynamic, linear_static or gaussian"
    mask = np.zeros(shape=(mask_size[1], mask_size[0]), dtype=np.float32)
    if mode == "gaussian":
        mu = np.sqrt(mask.shape[0]**2+mask.shape[1]**2)
        dev = mu / 3.5
        mask = _decay_value_radically_norm_in_matrix(mask_size, position, max_brightness, min_brightness, dev)
    mask = np.asarray(mask, dtype=np.uint8)
    # add median blur
    mask = cv2.medianBlur(mask, 5)
    mask = 255 - mask
    # cv2.imshow("mask", mask)
    # cv2.waitKey(0)
    return mask

def _decay_value_radically_norm_in_matrix(mask_size, centers, max_value, min_value, dev):
    """
    _decay_value_radically_norm function in matrix format
    """
    center_prob = norm.pdf(0, 0, dev)
    x_value_rate = np.zeros((mask_size[1], mask_size[0]))
    for center in centers:
        coord_x = np.arange(mask_size[0])
        coord_y = np.arange(mask_size[1])
        xv, yv = np.meshgrid(coord_x, coord_y)
        dist_x = xv - center[0]
        dist_y = yv - center[1]
        dist = np.sqrt(np.power(dist_x, 2) + np.power(dist_y, 2))
        x_value_rate += norm.pdf(dist, 0, dev) / center_prob
    mask = x_value_rate * (max_value - min_value) + min_value
    mask[mask > 255] = 255
    return mask

def _decay_value_radically_norm(x, centers, max_value, min_value, dev):
    """
    Calculate point value decayed from center following Gaussian decay. If multiple centers are given, value
    from each center sums up while limiting the accumulated value into [0, 255]
    NOTE: assuming light at each center is identical: same brightness and same decay rate
    """
    center_prob = norm.pdf(0, 0, dev)
    x_value_rate = 0
    for center in centers:
        distance = np.sqrt((center[0]-x[0])**2 + (center[1]-x[1])**2)
        x_value_rate += norm.pdf(distance, 0, dev) / center_prob
    x_value = x_value_rate * (max_value - min_value) + min_value
    x_value = 255 if x_value > 255 else x_value
    return x_value

def add_spot_light(image, light_position=None, max_brightness=255, min_brightness=0,
                   mode='gaussian', linear_decay_rate=None, transparency=None):
    """
    Add mask generated from spot light to given image
    """
    if transparency is None:
        transparency = random.uniform(0.5, 0.85)
    frame = np.copy(image)
    height, width, _ = frame.shape
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask = generate_spot_light_mask(mask_size=(width, height),
                                    position=light_position,
                                    max_brightness=max_brightness,
                                    min_brightness=min_brightness,
                                    mode=mode,
                                    linear_decay_rate=linear_decay_rate)
    hsv[:, :, 2] = hsv[:, :, 2] * transparency + mask * (1 - transparency)
    frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    frame[frame > 255] = 255
    frame = np.asarray(frame, dtype=np.uint8)
    return frame

def get_shadow(image_list):
    shadowed_list = []
    for image in image_list:
        shadowed_list.append(add_spot_light(image))
    return shadowed_list

# WARP #################################################################################################################

def warp_image(image: np.ndarray, amplitude_x: float = 5, amplitude_y: float = 5):
    # 원본 이미지 크기 가져오기
    height, width = image.shape[:2]

    # 사인파 주기 설정
    frequency_x = 1 / (width / 2)  # 수평 방향 주기를 이미지 폭의 한 파장으로 설정
    frequency_y = 1 / height  # 수직 방향 주기를 이미지 높이의 반파장으로 설정

    # 여유 공간을 추가하여 잘리는 부분 방지
    new_height = int(height + 2 * amplitude_y)
    new_width = int(width + 2 * amplitude_x)
    warped_image = np.zeros((new_height, new_width, *image.shape[2:]), dtype=image.dtype)

    # 이미지 중심 위치 계산
    y_offset = amplitude_y
    x_offset = amplitude_x

    # 각 픽셀 위치를 사인 함수에 따라 이동
    for y in range(height):
        for x in range(width):
            # 사인 함수를 사용하여 수평 및 수직 이동량 계산
            offset_x = int(amplitude_x * np.sin(2 * np.pi * frequency_y * y))  # 높이 기준 반파장
            offset_y = int(amplitude_y * np.sin(2 * np.pi * frequency_x * x))  # 폭 기준 한 파장

            # 새로운 좌표에 이미지 픽셀 배치 (여유 공간을 포함한 좌표)
            new_x = x + x_offset + offset_x
            new_y = y + y_offset + offset_y

            # 좌표가 유효한 범위 내에 있을 때만 픽셀 배치
            if 0 <= new_x < new_width and 0 <= new_y < new_height:
                warped_image[new_y, new_x] = image[y, x]

    return warped_image

def get_warp(image_list):
    warped_list = []
    for image in image_list:
        warped_list.append(warp_image(image))
    return warped_list

# MAIN #################################################################################################################
if __name__ == '__main__':
    class_num = 34  # 34가지 심전도 진단
    img_h = 1500  # 이미지 높이
    img_w = 3360  # 이미지 너비
    lead_len = 1024  # 입력 신호 길이
    lead_2_len = 4096  # Lead II 신호 길이
    diagnosis_classes = np.load('./examples/target_labels.npy', allow_pickle=True)  # 34가지 진단 레이블 및 순서

    lead_dir = './examples/examples_for_check_thresholding/image_dir'
    # directories = sorted(get_all_directories(lead_dir), key=sort_key)
    directories = ['MR000001']

    data_dir = './examples/examples_for_check_thresholding/'
    extracted_results = []
    target_results = []

    for i, dir_name in enumerate(directories):
        print(f'Processing : {i}/{len(directories)}...')
        lead_path = f'./examples/examples_for_check_thresholding/image_dir/{dir_name}'
        file_names = sorted([f for f in os.listdir(lead_path) if os.path.isfile(os.path.join(lead_path, f))],
                            key=sort_key)
        lead_list = get_image(lead_path, file_names)
        shadowed_list = get_shadow(lead_list)
        warped_list = get_warp(lead_list)

        result_path = f'./examples/examples_for_check_thresholding/final_diagnosis/'  # 최종 진단 결과 저장 경로
        result_image_path = result_path + f'{dir_name}.png'  # 최종 진단 결과 저장 경로
        result_path_with_target = f'./examples/examples_for_check_thresholding/final_diagnosis_with_target/'  # 최종 진단 결과 저장 경로
        result_image_path_with_target = result_path_with_target + f'{dir_name}.png'  # 최종 진단 결과 저장 경로
        denoised_image_path = f'./examples/examples_for_check_thresholding/denoised_image/'  # 잡음 제거 및 이진화 저장 경로
        denoised_path = denoised_image_path + f'{dir_name}.png'
        shadowed_image_path = f'./examples/examples_for_check_thresholding/shadowed_image/{dir_name}/'
        shadowed_result_path = f'./examples/examples_for_check_thresholding/shadowed_thresholding/'
        shadowed_result = shadowed_result_path + f'{dir_name}.png'
        warped_image_path = f'./examples/examples_for_check_thresholding/warped_image/{dir_name}/'
        warped_result_path = f'./examples/examples_for_check_thresholding/warped_thresholding/'
        warped_result = warped_result_path + f'{dir_name}.png'
        create_directory_if_empty(result_path)
        create_directory_if_empty(result_path_with_target)
        create_directory_if_empty(denoised_image_path)
        create_directory_if_empty(shadowed_image_path)
        create_directory_if_empty(shadowed_result_path)
        create_directory_if_empty(warped_image_path)
        create_directory_if_empty(warped_result_path)

        save_image_list(shadowed_image_path,dir_name,shadowed_list)
        save_image_list(warped_image_path, dir_name, warped_list)

        # Image denoising
        pad = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]
        denoised_img = Denoising(lead_list,pad=pad, path=denoised_path, DEVICE=DEVICE) # right image
        denoised_shadow = Denoising(shadowed_list,pad=pad, path=shadowed_result, DEVICE=DEVICE) # shadowed image
        denoised_shadow = Denoising(warped_list,pad=pad, path=warped_result, DEVICE=DEVICE) # warped image

    #     # Image to signal extraction (digitization)
    #     signals, lead_2 = Digitization(lead_list)
    #
    #     # ECG classification
    #     result, extracted_signals = Classifier(signals, lead_2, class_num, lead_len=lead_len, lead_2_len=lead_2_len,
    #                                            DEVICE=DEVICE)
    #     result_target, raw_signals = ClassifierRaw(dir_name, class_num, lead_len=lead_len, lead_2_len=lead_2_len,
    #                                                DEVICE=DEVICE)
    #
    #     # Plot outputs of the model
    #     plot_results(result.cpu().numpy(),
    #                  extracted_signals.squeeze(0).cpu().numpy(),
    #                  np.expand_dims(lead_2, axis=0),
    #                  diagnosis_classes,
    #                  result_image_path)  # 이미지 추출 신호로부터 진단 시긱화
    #
    #     plot_results_with_target(result.cpu().numpy(),
    #                              result_target.cpu().numpy(),
    #                              extracted_signals.squeeze(0).cpu().numpy(),
    #                              raw_signals.squeeze(0).cpu().numpy(),
    #                              diagnosis_classes,
    #                              result_image_path_with_target)  # 이미지 추출 신호, 원본 신호로부터 진단 시각화
    #
    #     extracted_results.append(result.cpu().numpy())
    #     target_results.append(result_target.cpu().numpy())
    #
    # save_data(diagnosis_classes, data_list=directories, extracted_result_list=extracted_results,
    #           target_result_list=target_results, dir=data_dir, filename="diagnosis_results.xlsx")


print(f"{time.time() - start:.5f} sec")  # CPU : 48.6초 소요